<!doctype html>
<html lang="en-US">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0" />
        <meta name="description" content="**FRIEREN**, a novel no-reference image quality assessment, effectively and accurately evaluates the face detail quality scaled by different interpolations with low computational complexity. From human perception, the ranking of detail qualities should be: **Lanczos &gt; bicubic &gt; bilinear &gt; nearest-neighbor** interpolation. It is recommended to zoom in on-screen to observe the different visual effects of different interpolations." />
        <meta property="og:title" content="FRIEREN: A Lightweight System for Face Resizing Image Detail Quality Evaluation via Robust Estimation of Image Naturalness" />
        <meta property="og:description" content="**FRIEREN**, a novel no-reference image quality assessment, effectively and accurately evaluates the face detail quality scaled by different interpolations with low computational complexity. From human perception, the ranking of detail qualities should be: **Lanczos &gt; bicubic &gt; bilinear &gt; nearest-neighbor** interpolation. It is recommended to zoom in on-screen to observe the different visual effects of different interpolations." />
        <meta property="og:url" content="https://NTUneillee.github.io/research/friereniqa/" />
        
        <meta property="og:image" content="https://NTUneillee.github.io/images/post/FRIERENlogo.webp" />
        
        <meta property="og:image:width" content="1200" />
        <meta property="og:image:height" content="630" />

        <meta name="twitter:title" content="FRIEREN: A Lightweight System for Face Resizing Image Detail Quality Evaluation via Robust Estimation of Image Naturalness" />
        <meta name="twitter:description" content="**FRIEREN**, a novel no-reference image quality assessment, effectively and accurately evaluates the face detail quality scaled by different interpolations with low computational complexity. From human perception, the ranking of detail qualities should be: **Lanczos &gt; bicubic &gt; bilinear &gt; nearest-neighbor** interpolation. It is recommended to zoom in on-screen to observe the different visual effects of different interpolations." />
        
        <meta name="twitter:image" content="https://NTUneillee.github.io/images/post/FRIERENlogo.webp" />
        
        <meta name="twitter:card" content="summary_large_image" />
        <meta name="keywords" content="Camera Image Quality, Image Processing, Color Science" />
        <title>FRIEREN: A Lightweight System for Face Resizing Image Detail Quality Evaluation via Robust Estimation of Image Naturalness</title>

        <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />

        <link rel="stylesheet" href="https://NTUneillee.github.io/academic-assets/css/spf-bulma.min.css" />
        <link rel="stylesheet" href="https://NTUneillee.github.io/academic-assets/css/fontawesome.all.min.css" />
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.5/css/academicons.min.css" integrity="sha256-SzrCOBJbGVFMahewkgjwnApaV2+av1DwMAA+/QGLyZw=" crossorigin="anonymous" />
        <link rel="stylesheet" href="https://NTUneillee.github.io/academic-assets/css/spf-index.css" />

        <script src="https://cdn.jsdelivr.net/npm/jquery@3.7.1/dist/jquery.min.js" integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script>
        <script defer src="https://NTUneillee.github.io/academic-assets/js/fontawesome.all.min.js"></script>

        <script>
            window.MathJax = {
                tex: {
                    inlineMath: [["$", "$"]],
                },
                chtml: {
                    scale: 1.1,
                    mtextInheritFont: true,
                },
                svg: {
                    fontCache: 'global'
                }
            };
        </script>
        <script id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@4.0.0/tex-mml-chtml.js" integrity="sha256-qoRlVrS5NAnXSSSiMfFXwK8C9obG11Iybe4h2+bQYR4=" crossorigin="anonymous"></script>

        <style>
             
            mjx-container {
                -webkit-font-smoothing: antialiased;
                -moz-osx-font-smoothing: grayscale;
            }

            mjx-container svg {
                shape-rendering: geometricPrecision;
            }

             
            .method-image-container,
            .results-image-container {
                display: inline-block;
                border: 1px solid #e0e0e0;
                border-radius: 12px;
                padding: 1rem;
                background-color: #f5f5f5;
                box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
                margin: 1.5rem 0;
            }

             
            .hero.is-light .method-image-container,
            .hero.is-light .results-image-container {
                border: 1px solid #e0e0e0;
                background-color: #ffffff;
                box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
            }

            .method-image-container img,
            .results-image-container img {
                border-radius: 8px;
                max-width: 100%;
                height: auto;
                display: block;
            }

            .publication-title {
                line-height: 1.5 !important;
            }

             
            .container.is-max-desktop {
                max-width: 1080px;
            }

            .columns.is-centered {
                justify-content: center;
            }

             
            img {
                max-width: 100% !important;
                height: auto !important;
                width: 100% !important;
            }

             
            .hero-body {
                padding-left: 0;
                padding-right: 0;
            }

             
            .hero.teaser {
                padding-top: 0;
                margin-top: 0;
            }

            .hero.teaser .hero-body {
                padding-top: 0;
            }

            .card-container {
                padding-left: 0 !important;
                padding-right: 0 !important;
            }

             
            .title.is-1 {
                font-size: 2.5rem;
            }

             
            .publication-authors:has(.eql-cntrb) {
                margin-bottom: 0.5rem !important;
            }

            .column.has-text-centered {
                margin-top: 0;
                padding-top: 0.5rem;
            }

             
            #BibTeX pre {
                overflow-x: auto;
                white-space: pre;
                word-wrap: normal;
                width: 100%;
                display: block;
                box-sizing: border-box;
                margin: 0;
                padding: 1.25rem;
                background-color: #ffffff;
                border: 1px solid #e0e0e0;
                border-radius: 4px;
            }

            #BibTeX code {
                white-space: pre;
                word-wrap: normal;
                display: block;
            }

            #BibTeX .column {
                width: 100%;
            }

             
            .content mjx-container[jax="CHTML"][display="false"] {
                display: inline !important;
                vertical-align: baseline !important;
                margin: 0 !important;
            }

            .content mjx-container {
                line-height: 0 !important;
            }

             
            .content mjx-container[jax="CHTML"][display="true"] {
                overflow-x: auto;
                overflow-y: hidden;
                max-width: 100%;
                display: block !important;
            }

             
            @media screen and (min-width: 769px) {
                .hero.teaser .subtitle.content {
                    font-size: 1.125rem !important;
                    line-height: 1.7 !important;
                }

                .content,
                .content p,
                .content li {
                    font-size: 1.125rem !important;
                    line-height: 1.7 !important;
                }
            }

             
            @media screen and (max-width: 768px) {
                 
                html {
                    font-size: 16px !important;
                }

                body {
                    font-size: 1rem !important;
                    line-height: 1.6 !important;
                }


                .hero-body {
                    padding: 2rem 0.75rem !important;
                }

                .title.is-1 {
                    font-size: 1.75rem !important;
                    line-height: 1.3 !important;
                    margin-bottom: 1rem !important;
                }

                .title.is-3 {
                    font-size: 1.5rem !important;
                    line-height: 1.3 !important;
                    margin-bottom: 1rem !important;
                }

                .title.is-5 {
                    font-size: 1.125rem !important;
                    line-height: 1.4 !important;
                }

                .is-size-4 {
                    font-size: 1.25rem !important;
                    line-height: 1.4 !important;
                }

                .is-size-5 {
                    font-size: 1.0625rem !important;
                    line-height: 1.5 !important;
                }

                .subtitle {
                    font-size: 1.0625rem !important;
                    line-height: 1.7 !important;
                }

                .content,
                .content p,
                .content li {
                    font-size: 1.0625rem !important;
                    line-height: 1.7 !important;
                }

                .content h3 {
                    font-size: 1.25rem !important;
                    margin-top: 1.5rem !important;
                    margin-bottom: 0.75rem !important;
                }

                .content h4 {
                    font-size: 1.125rem !important;
                    margin-top: 1.25rem !important;
                    margin-bottom: 0.75rem !important;
                }

                .container.is-max-desktop {
                    padding-left: 0.75rem !important;
                    padding-right: 0.75rem !important;
                    max-width: 100% !important;
                }

                .section {
                    padding: 2.5rem 0.75rem !important;
                }

                .columns {
                    margin: 0 !important;
                }

                .column {
                    padding: 0 0.75rem !important;
                }

                .column.is-half {
                    width: 100% !important;
                }

                .column.is-four-fifths {
                    width: 100% !important;
                }

                .publication-links .link-block {
                    display: inline-block;
                    margin-bottom: 0;
                    margin-right: 0.5rem;
                }

                .publication-links .button {
                    width: auto;
                    font-size: 1.0625rem !important;
                    padding: 0.5rem 0.75rem !important;
                }

                iframe {
                    width: 100% !important;
                    height: auto !important;
                    aspect-ratio: 16 / 9;
                }

                pre {
                    font-size: 0.875rem;
                    overflow-x: auto;
                    padding: 1rem !important;
                    margin: 0 !important;
                    border-radius: 4px !important;
                    width: 100% !important;
                    box-sizing: border-box !important;
                }

                pre code {
                    font-size: 0.875rem !important;
                }

                #BibTeX .column {
                    padding: 0 0.75rem !important;
                    width: 100% !important;
                }

                #BibTeX pre {
                    margin: 0 !important;
                    width: 100% !important;
                }

                .card-container {
                    padding: 1.5rem !important;
                    margin-bottom: 2rem !important;
                    margin-left: 0 !important;
                    margin-right: 0 !important;
                }

                .card-container h4 {
                    font-size: 1.5rem !important;
                }

                .card-container p,
                .card-container li {
                    font-size: 1.25rem !important;
                }

                 
                .has-text-justified {
                    text-align: left !important;
                }

                 
                .hero,
                .section {
                    overflow-x: hidden !important;
                }

                img {
                    max-width: 100% !important;
                    height: auto !important;
                }
            }
        </style>
    </head>

    <body>
        <section class="hero">
            <div class="hero-body">
                <div class="container is-max-desktop">
                    <div class="columns is-centered">
                        <div class="column has-text-centered">
                            <h1 class="title is-1 publication-title">
                                FRIEREN: A Lightweight System for Face Resizing Image Detail Quality Evaluation via Robust Estimation of Image Naturalness
                            </h1>
                            
                            <div class="is-size-4 publication-authors" style="margin-bottom: 0.5rem;">
                                <span class="conference-block">IEEE APCCAS 2025</span>
                            </div>
                            

                            <div class="is-size-5 publication-authors" style="margin-bottom: 0.5rem;">
                                
                                
                                <span class="author-block">
                                    
                                    <a href="https://ntuneillee.github.io/" target="_blank">Yuan-Kang Lee*</a>
                                    
                                    
                                    ,
                                </span>
                                
                                <span class="author-block">
                                    
                                    <a href="https://brianchen1120.github.io" target="_blank">Kuan-Lin Chen*</a>
                                    
                                    
                                    ,
                                </span>
                                
                                <span class="author-block">
                                    
                                    <a href="https://www.ee.ntu.edu.tw/profile1.php?teacher_id=942019" target="_blank">Jian-Jiun Ding</a>
                                    
                                    
                                    
                                </span>
                                
                                
                            </div>

                            <div class="is-size-5 publication-authors" style="margin-bottom: 0.5rem;">
                                
                                
                                <span class="author-block">Graduate Institute of Communication Engineering, National Taiwan University</span>
                                
                                
                                
                            </div>

                            
                            <div class="is-size-5 publication-authors" style="margin-bottom: 0.25rem;">
                                <span class="eql-cntrb"><small><sup>*</sup>Indicates Equal Contribution</small></span>
                            </div>
                            

                            <div class="column has-text-centered" style="margin-top: 0; padding-top: 0.5rem;">
                                <div class="publication-links">
                                    

                                    

                                    

                                    
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section class="hero teaser">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column">
                        <div class="hero-body">
                            
                            <img src="https://NTUneillee.github.io/images/post/FRIERENlogo.webp" alt="FRIEREN: A Lightweight System for Face Resizing Image Detail Quality Evaluation via Robust Estimation of Image Naturalness" style="width: 100%; display: block;" />
                            
                            <div class="subtitle has-text-centered content" style="width: 100%; margin-top: 1.5rem; line-height: 1.7;">
                                <strong>FRIEREN</strong>, a novel no-reference image quality assessment, effectively and accurately evaluates the face detail quality scaled by different interpolations with low computational complexity. From human perception, the ranking of detail qualities should be: <strong>Lanczos &gt; bicubic &gt; bilinear &gt; nearest-neighbor</strong> interpolation. It is recommended to zoom in on-screen to observe the different visual effects of different interpolations.
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        
        <section class="section hero is-light">
            <div class="container is-max-desktop">
                <div class="columns is-centered has-text-centered">
                    <div class="column">
                        <h2 class="title is-3">Abstract</h2>
                        <div class="content has-text-justified">
                            In real-time video conferencing systems, webcams often apply image resizing methods, such as nearest-neighbor, bilinear, bicubic, and Lanczos interpolation, to highlight facial regions and enhance user experience. However, interpolations introduce significant high-frequency artifacts that distort perceived image quality. Our work discovered that existing state-of-the-art image quality assessments (IQA) greatly overestimate the sharpness in images resized by nearest-neighbor interpolation, failing to extract useful information in the image’s high-frequency components. To address this, we propose FRIEREN (Face Resizing Image Detail Quality Evaluation via Robust Estimation of Image Naturalness), a novel IQA for detail quality evaluation that integrates measures of image naturalness, including motion noise, spatial noise, and HVS-based sharpness. Designed features are fed to Kolmogorov-Arnold Networks (KANs) for quality prediction. Experimental results show that FRIEREN effectively and accurately evaluates the face image detail quality scaled by different interpolations with low computational complexity,making it suitable for quality-aware vision systems.
                        </div>
                    </div>
                </div>
            </div>
        </section>
        

        
        <section class="section">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column">
                        <h2 class="title is-3 has-text-centered">Problem Formulation</h2>
                        <div class="content has-text-justified">
                            <p>It can be observed that the
face image enlarged by the nearest-neighbor method is heavily
affected by severe block artifacts. Existing advanced IQAs
mistakenly interpret noise-related high-frequency components as textures, underscoring a critical limitation in their ability
to distinguish useful high-frequency information in images. To overcome this drawback, FRIEREN is based on two main observations of the human visual system:</p>
<ul>
<li>
<p>Edge-related high-frequency elements are the most important factors in how humans evaluate image sharpness.</p>
</li>
<li>
<p>For the HVS perception, the ranking of detail quality
levels in facial images after applying different interpolations is as follows: Lanczos, bicubic, bilinear, and nearest-neighbor method (from the best to the worst).</p>
</li>
</ul>
<p>To the best of our knowledge, our work is the first one that addresses interpolation effects on facial image quality. The detail quality degradation induced by interpolation can be quantified using our proposed motion and spatial noises and HVS-based sharpness calculation effectively.</p>

                        </div>
                    </div>
                </div>
            </div>
        </section>
        

        

        
        <section class="section hero is-light">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column">
                        <h2 class="title is-3 has-text-centered">Method Overview</h2>
                        <div class="content has-text-justified">
                            <h3 id="quality-evaluation-using-kans">Quality Evaluation using KANs</h3>
<p>Predicting image quality requires a regression model that maps features to quality scores to enhance alignment with human visual judgment. We employ Kolmogorov-Arnold Networks (KANs) for the regression in FRIEREN. KANs,
based on the Kolmogorov-Arnold theorem, differ from MLPs by avoiding linear outputs. It enables KANs to effectively capture non-linear relationships, making them a way better regression model for simulating human perception. We use
the Adam (Adaptive moment estimation) optimizer with $\beta_1$ = 0.9 and $\beta_2$ = 0.999 to update the model parameters for optimal quality prediction performance. To train the quality prediction model, 64% of the images were randomly selected for training, with 16% used for validation and the remaining 20% for testing. The proposed image features: motion noise, spatial noise, and HVS-based sharpness measure in FRIEREN are introduced in the following sections.</p>
<h3 id="feature-motion-noise-estimation">Feature: Motion Noise Estimation</h3>
<p>High-level temporal noise disrupts visual understanding of
multimedia content. It cannot be completely eliminated due
to the sensor limitations and environmental conditions. Hence,
determining the effect of temporal noise is essential to quantify
the facial details that a camera can reproduce in images. To
adapt FRIEREN into a no-reference method, motion noise
is introduced to calculate the temporal noise influence using
only one single image frame. Frame modification is applied
for motion noise estimation. Denoted $I$ as the original image
frame. By discarding the last row and column of pixels from
$I$, the new image frame $I’$ with slightly different content is
created. Then, image frames $I$ and $I’$ are both enlarged to the
same dimensions, simulating motion variations typically seen
in a video sequence. Let $D$ be denoted as the absolute pixel-wise difference between the two frames. The motion noise of the image frame, $\sigma_m$, is calculated as:</p>
<p>$$ \sigma_m = \sqrt{ \frac{1}{M \cdot N} \sum_{i=1}^{M} \sum_{j=1}^{N} (D_{ij} - \mu_D)^2 } $$</p>
<p>where $\mu_D$ represents the average of the frame difference and $M$ and $N$ are the height and width of $I$, respectively.</p>
<h3 id="feature-spatial-noise-estimation">Feature: Spatial Noise Estimation</h3>

  <div class="has-text-centered" style="margin: 1.5rem 0;">
      <div class="method-image-container">
          <img src="https://NTUneillee.github.io/academic-assets/images/ProposedNoiseEst.webp" alt="**Spatial noise estimation framework in FRIEREN**: By excluding the edge-related components in high frequency layers, the DWT-based spatial noise estimation enables FRIEREN to quantify the level of noise in an image effectively and accurately." />
          
          <p style="margin-top: 1rem; font-size: 0.95rem; color: #666; line-height: 1.6;"><strong>Spatial noise estimation framework in FRIEREN</strong>: By excluding the edge-related components in high frequency layers, the DWT-based spatial noise estimation enables FRIEREN to quantify the level of noise in an image effectively and accurately.</p>
          
      </div>
  </div>

<p>The 2D Discrete Wavelet Transform (DWT) decomposes an image into LL, LH, HL, and HH sub-bands, capturing varying detail levels. High-frequency information, including noise and edges, is contained in the LH, HL, and HH sub-bands. Effective noise estimation depends on the ability to distinguish noise from these high-frequency components. By removing edges in the LH, HL, and HH layers, the noisy components can be identified. Denote $LL_i$, $LH_i$, $HL_i$, and $HH_i$ as frequency layers obtained at decomposition level $i$ in the 2D DWT process. Let $EM$ be the edge detection result applied to the $LL_i$ layer, and $IEM$ be the inverted edge mask. The noise energy map $NEM$ is expressed as</p>
<p>$$IEM = 1 - EM$$
$$NEM = \sqrt{a \cdot LH_i^2 + b \cdot HL_i^2 + c \cdot HH_i^2} \cdot IEM$$</p>
<p>where $a$, $b$, and $c$ are weighting parameters for regulating the influence of $LH_i$, $HL_i$, and $HH_i$ coefficients, respectively.</p>
<p>Noise dominates the edges when an image suffers from severe noise, causing underestimation in the noise influence evaluation. Our proposed approach addresses this problem by recognizing that varying noise energy distributions require different quantiles to identify the most representative energy data for estimation. In real-world scenarios such as video conferencing, image enlargement is commonly applied when a face appears in a frame to make the subject more visually prominent. Since faces before the enlargement are relatively small in the scene, they inherently contain a constrained amount of visual details. Higher decomposition levels can reveal subtle features that might be missed at lower levels, improving the noise estimation performance within small face images. We use the decomposition level of 3 in our method. The edge mask $EM$ is obtained by applying the Sobel operator on the $LL_3$ layer.</p>
<h3 id="feature-hvs-based-sharpness-measure">Feature: HVS-based Sharpness Measure</h3>
<p>Sharpness determines how well-defined the textures and
edges of objects appear in images. Inspired by the previous
task of spatial noise estimation, our proposed image sharpness measure integrates the spatial-domain and transform-domain methods. We employ edge detection on the image’s low-frequency sub-band to effectively capture the edge-related high-frequency components that contain the critical sharpness information. Three levels of DWT edge-related high-frequency sub-bands are then incorpo-
rated into the sharpness calculation. The method, which combines spatial and transform domain information, minimizes the impact of noise as much as possible while emphasizing the importance of edge features when calculating image clarity.</p>

                        </div>
                        
                    </div>
                </div>
            </div>
        </section>
        

        
        <section class="section">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column">
                        <h2 class="title is-3 has-text-centered">Results</h2>
                        <div class="content has-text-justified">
                            
<div class="has-text-centered" style="margin: 1.5rem 0;">
    <div class="method-image-container">
        <img src="https://NTUneillee.github.io/academic-assets/images/TestScene.webp" alt="**Mannequin dataset**: Three realistic mannequins are used in part of our experiments. To prevent any impact from post-processing on facial details, all images are captured in RAW format using a Sony IMX383-AAQK image sensor." />
        
        <p style="margin-top: 1rem; font-size: 0.95rem; color: #666; line-height: 1.6;"><strong>Mannequin dataset</strong>: Three realistic mannequins are used in part of our experiments. To prevent any impact from post-processing on facial details, all images are captured in RAW format using a Sony IMX383-AAQK image sensor.</p>
        
    </div>
</div>

<p>We utilize two face image datasets in our experiments: our
collected mannequin face images and the MS1MV2 dataset. Our dataset validates quality degradation due to interpolation, while MS1MV2 demonstrates FRIEREN’s effectiveness compared to other IQA methods. In our dataset, gamma
correction is applied to generate additional face images, which
are enlarged using nearest-neighbor, bilinear, bicubic, and
Lanczos interpolation at scales from 2× to 5× (step 0.5). For
MS1MV2, 10,000 randomly selected images are upscaled to
2× using all four methods.</p>
<h3 id="performance-evaluation">Performance Evaluation</h3>
<p>FRIEREN demonstrates superior performance compared to existing IQA methods:</p>
<ul>
<li><strong>Accuracy</strong>: High correlation with human subjective scores (PLCC &gt; 0.90)</li>
<li><strong>Efficiency</strong>: Processing time reduced by 60% compared to state-of-the-art methods</li>
<li><strong>Robustness</strong>: Consistent performance across different interpolation algorithms</li>
</ul>
<h3 id="key-findings">Key Findings</h3>
<ol>
<li>The system accurately identifies quality degradation in resized face images</li>
<li>Low computational complexity makes it suitable for real-time applications</li>
<li>Robust across various scaling factors and interpolation methods</li>
</ol>

                        </div>
                        
                    </div>
                </div>
            </div>
        </section>
        

        
        <section class="section hero is-light" id="BibTeX">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column">
                        <h2 class="title is-3 has-text-centered">BibTeX</h2>
                        <pre><code>@inproceedings{frieren2025,
  title = {FRIEREN: A Lightweight System for Face Resizing Image Detail Quality Evaluation via Robust Estimation of Image Naturalness},
  author = {Yuan-Kang Lee and Kuan-Lin Chen and Jian-Jiun Ding},
  booktitle = {IEEE Asia Pacific Conference on Circuits and Systems (APCCAS)},
  year = {2025},
  pages = {to appear},
  url = {https://ntuneillee.github.io/research/friereniqa/}
}
</code></pre>
                    </div>
                </div>
            </div>
        </section>
        

        <footer class="footer">
            <div class="container">
                <div class="columns is-centered">
                    <div class="column is-8">
                        <div class="content has-text-centered">
                            <p>
                                This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
                                <br />This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </footer>
    </body>
</html>

<!doctype html>
<html lang="en-US">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0" />
        <meta name="description" content="We present RL-AWB, a novel framework combining statistical methods with deep reinforcement learning for nighttime white balance. We also contribute LEVI, the first multi-sensor nighttime dataset for color constancy in this work." />
        <meta property="og:title" content="RL-AWB: Deep Reinforcement Learning for Auto White Balance Correction in Low-Light Night-time Scenes" />
        <meta property="og:description" content="We present RL-AWB, a novel framework combining statistical methods with deep reinforcement learning for nighttime white balance. We also contribute LEVI, the first multi-sensor nighttime dataset for color constancy in this work." />
        <meta property="og:url" content="https://NTUneillee.github.io/research/rl-awb/" />
        
        <meta property="og:image" content="https://NTUneillee.github.io/academic-assets/images/RLAWB_logo.webp" />
        
        <meta property="og:image:width" content="1200" />
        <meta property="og:image:height" content="630" />

        <meta name="twitter:title" content="RL-AWB: Deep Reinforcement Learning for Auto White Balance Correction in Low-Light Night-time Scenes" />
        <meta name="twitter:description" content="We present RL-AWB, a novel framework combining statistical methods with deep reinforcement learning for nighttime white balance. We also contribute LEVI, the first multi-sensor nighttime dataset for color constancy in this work." />
        
        <meta name="twitter:image" content="https://NTUneillee.github.io/academic-assets/images/RLAWB_logo.webp" />
        
        <meta name="twitter:card" content="summary_large_image" />
        <meta name="keywords" content="Camera Image Quality, Image Processing, Color Science, Deep Learning" />
        <title>RL-AWB: Deep Reinforcement Learning for Auto White Balance Correction in Low-Light Night-time Scenes</title>

        <!--Favicon-->
        <link rel="shortcut icon" href="https://NTUneillee.github.io/images/fujisan.png?v=5" type="image/x-icon">
        <link rel="icon" href="https://NTUneillee.github.io/images/fujisan.png?v=5" type="image/x-icon">

        <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />

        <link rel="stylesheet" href="https://NTUneillee.github.io/academic-assets/css/spf-bulma.min.css" />
        <link rel="stylesheet" href="https://NTUneillee.github.io/academic-assets/css/fontawesome.all.min.css" />
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.5/css/academicons.min.css" integrity="sha256-SzrCOBJbGVFMahewkgjwnApaV2+av1DwMAA+/QGLyZw=" crossorigin="anonymous" />
        <link rel="stylesheet" href="https://NTUneillee.github.io/academic-assets/css/spf-index.css" />

        <script src="https://cdn.jsdelivr.net/npm/jquery@3.7.1/dist/jquery.min.js" integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script>
        <script defer src="https://NTUneillee.github.io/academic-assets/js/fontawesome.all.min.js"></script>

        <script>
            window.MathJax = {
                tex: {
                    inlineMath: [["$", "$"]],
                },
                chtml: {
                    scale: 1.1,
                    mtextInheritFont: true,
                },
                svg: {
                    fontCache: 'global'
                }
            };
        </script>
        <script id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@4.0.0/tex-mml-chtml.js" integrity="sha256-qoRlVrS5NAnXSSSiMfFXwK8C9obG11Iybe4h2+bQYR4=" crossorigin="anonymous"></script>

        <style>
             
            mjx-container {
                -webkit-font-smoothing: antialiased;
                -moz-osx-font-smoothing: grayscale;
            }

            mjx-container svg {
                shape-rendering: geometricPrecision;
            }

             
            .method-image-container,
            .results-image-container {
                display: inline-block;
                border: 1px solid #e0e0e0;
                border-radius: 12px;
                padding: 1rem;
                background-color: #f5f5f5;
                box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
                margin: 0.75rem 0;
            }

             
            .hero.is-light .method-image-container,
            .hero.is-light .results-image-container {
                border: 1px solid #e0e0e0;
                background-color: #ffffff;
                box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
            }

            .method-image-container img,
            .results-image-container img {
                border-radius: 8px;
                max-width: 100%;
                height: auto;
                display: block;
            }

            .publication-title {
                line-height: 1.5 !important;
            }

             
            .publication-authors .author-block sup {
                margin-left: 0.1em !important;
                margin-right: 0 !important;
                padding-left: 0 !important;
            }

             
            .publication-authors .author-block a + sup,
            .publication-authors .author-block span + sup {
                margin-left: 0.1em !important;
            }

             
            .container.is-max-desktop {
                max-width: 1080px;
            }

            .columns.is-centered {
                justify-content: center;
            }

             
            img {
                max-width: 100% !important;
                height: auto !important;
                width: 100% !important;
            }

             
            .hero-body {
                padding-left: 0;
                padding-right: 0;
            }

             
            .hero.teaser {
                padding-top: 0;
                margin-top: 0;
            }

            .hero.teaser .hero-body {
                padding-top: 0;
            }

            .card-container {
                padding-left: 0 !important;
                padding-right: 0 !important;
            }

             
            .title.is-1 {
                font-size: 2.5rem;
            }

             
            .publication-authors:has(.eql-cntrb) {
                margin-bottom: 0.5rem !important;
            }

            .column.has-text-centered {
                margin-top: 0;
                padding-top: 0.5rem;
            }

             
            section#BibTeX pre {
                overflow-x: auto;
                white-space: pre;
                word-wrap: normal;
                width: 100%;
                display: block;
                box-sizing: border-box;
                margin: 0;
                padding: 1.25rem;
                border: 1px solid #e0e0e0;
                border-radius: 4px;
            }

             
            section.hero.is-light#BibTeX pre {
                background-color: #ffffff;
            }

             
            section#BibTeX:not(.is-light) pre {
                background-color: #f5f5f5;
            }

            #BibTeX code {
                white-space: pre;
                word-wrap: normal;
                display: block;
            }

            #BibTeX .column {
                width: 100%;
            }

             
            .content mjx-container[jax="CHTML"][display="false"] {
                display: inline !important;
                vertical-align: baseline !important;
                margin: 0 !important;
            }

            .content mjx-container {
                line-height: 0 !important;
            }

             
            .content mjx-container[jax="CHTML"][display="true"] {
                overflow-x: auto;
                overflow-y: hidden;
                max-width: 100%;
                display: block !important;
            }

             
            .table-wrapper {
                width: 100%;
                overflow-x: auto;
                -webkit-overflow-scrolling: touch;
                margin: 1rem 0;
            }

             
            .content table {
                border-collapse: collapse;
                width: 100%;
                display: table;
                border-top: 2px solid #666666;
                border-bottom: 2px solid #666666;
            }

            .content table th,
            .content table td {
                white-space: nowrap;
            }

             
            @media screen and (min-width: 769px) {
                .hero.teaser .subtitle.content {
                    font-size: 1rem !important;
                    line-height: 1.7 !important;
                }

                .content,
                .content p,
                .content li {
                    font-size: 1rem !important;
                    line-height: 1.7 !important;
                }
            }

             
            @media screen and (max-width: 768px) {
                 
                html {
                    font-size: 16px !important;
                }

                body {
                    font-size: 1rem !important;
                    line-height: 1.6 !important;
                }


                .hero-body {
                    padding: 2rem 0.75rem !important;
                }

                .title.is-1 {
                    font-size: 1.75rem !important;
                    line-height: 1.3 !important;
                    margin-bottom: 1rem !important;
                }

                .title.is-3 {
                    font-size: 1.5rem !important;
                    line-height: 1.3 !important;
                    margin-bottom: 1rem !important;
                }

                .title.is-5 {
                    font-size: 1.125rem !important;
                    line-height: 1.4 !important;
                }

                .is-size-4 {
                    font-size: 1.25rem !important;
                    line-height: 1.4 !important;
                }

                .is-size-5 {
                    font-size: 1.0625rem !important;
                    line-height: 1.5 !important;
                }

                .subtitle {
                    font-size: 1rem !important;
                    line-height: 1.6 !important;
                }

                .content,
                .content p,
                .content li {
                    font-size: 1rem !important;
                    line-height: 1.8 !important;
                }

                .content h3 {
                    font-size: 1.25rem !important;
                    margin-top: 1.5rem !important;
                    margin-bottom: 0.75rem !important;
                }

                .content h4 {
                    font-size: 1.125rem !important;
                    margin-top: 1.25rem !important;
                    margin-bottom: 0.75rem !important;
                }

                .container.is-max-desktop {
                    padding-left: 0.75rem !important;
                    padding-right: 0.75rem !important;
                    max-width: 100% !important;
                }

                .section {
                    padding: 2.5rem 0.75rem !important;
                }

                .columns {
                    margin: 0 !important;
                }

                .column {
                    padding: 0 0.75rem !important;
                }

                .column.is-half {
                    width: 100% !important;
                }

                .column.is-four-fifths {
                    width: 100% !important;
                }

                .publication-links .link-block {
                    display: inline-block;
                    margin-bottom: 0;
                    margin-right: 0.5rem;
                }

                .publication-links .button {
                    width: auto;
                    font-size: 1.0625rem !important;
                    padding: 0.5rem 0.75rem !important;
                }

                iframe {
                    width: 100% !important;
                    height: auto !important;
                    aspect-ratio: 16 / 9;
                }

                pre {
                    font-size: 0.875rem;
                    overflow-x: auto;
                    padding: 1rem !important;
                    margin: 0 !important;
                    border-radius: 4px !important;
                    width: 100% !important;
                    box-sizing: border-box !important;
                }

                pre code {
                    font-size: 0.875rem !important;
                }

                #BibTeX .column {
                    padding: 0 0.75rem !important;
                    width: 100% !important;
                }

                #BibTeX pre {
                    margin: 0 !important;
                    width: 100% !important;
                }

                .card-container {
                    padding: 1.5rem !important;
                    margin-bottom: 2rem !important;
                    margin-left: 0 !important;
                    margin-right: 0 !important;
                }

                .card-container h4 {
                    font-size: 1.5rem !important;
                }

                .card-container p,
                .card-container li {
                    font-size: 1.25rem !important;
                }

                 
                .has-text-justified {
                    text-align: left !important;
                }

                 
                .hero,
                .section {
                    overflow-x: hidden !important;
                }

                img {
                    max-width: 100% !important;
                    height: auto !important;
                }
            }
        </style>
    </head>

    <body>
        <section class="hero">
            <div class="hero-body">
                <div class="container is-max-desktop">
                    <div class="columns is-centered">
                        <div class="column has-text-centered">
                            <h1 class="title is-1 publication-title">
                                RL-AWB: Deep Reinforcement Learning for Auto White Balance Correction in Low-Light Night-time Scenes
                            </h1>
                            
                            <div class="is-size-4 publication-authors" style="margin-bottom: 0.5rem;">
                                <span class="conference-block">arXiv 2026</span>
                            </div>
                            

                            <div class="is-size-5 publication-authors" style="margin-bottom: 0.5rem;">
                                
                                
                                <span class="author-block"><strong><a href="https://ntuneillee.github.io/" target="_blank">Yuan-Kang Lee</a></strong><sup>1,3*</sup>,
                                </span>
                                
                                <span class="author-block"><a href="https://brianchen1120.github.io" target="_blank">Kuan-Lin Chen</a><sup>2,3*</sup>,
                                </span>
                                
                                <span class="author-block"><a href="https://scholar.google.com.tw/citations?user=FK1RcpoAAAAJ" target="_blank">Chia-Che Chang</a><sup>1</sup>,
                                </span>
                                
                                <span class="author-block"><a href="https://yulunalexliu.github.io" target="_blank">Yu-Lun Liu</a><sup>3</sup>
                                </span>
                                
                                
                            </div>

                            <div class="is-size-5 publication-authors" style="margin-bottom: 0.5rem;">
                                
                                
                                <span class="author-block"><sup>1</sup>MediaTek Inc.</span>, 
                                
                                <span class="author-block"><sup>2</sup>National Taiwan University</span>, 
                                
                                <span class="author-block"><sup>3</sup>National Yang Ming Chiao Tung University</span>
                                
                                
                            </div>
                            <div class="is-size-5 publication-authors" style="margin-bottom: 0.25rem;">
                                <span class="eql-cntrb"><small><sup>*</sup>Indicates Equal Contribution</small></span>
                            </div>
                            

                            <div class="column has-text-centered" style="margin-top: 0; padding-top: 0.5rem;">
                                <div class="publication-links">
                                    

                                    
                                    <span class="link-block">
                                        <a href="https://ntuneillee.github.io/research/rl-awb/" target="_blank" class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon"><i class="ai ai-arxiv"></i></span>
                                            <span>arXiv</span>
                                        </a>
                                    </span>
                                    

                                    
                                    <span class="link-block">
                                        <a href="https://github.com/BrianChen1120/RL-AWB" target="_blank" class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon"><i class="fab fa-github"></i></span>
                                            <span>Code</span>
                                        </a>
                                    </span>
                                    

                                    

                                    
                                    <span class="link-block">
                                        <a href="https://drive.google.com/drive/folders/1VeqcIhkr83gL_ZF5DMnvFsmXyC4QhSro" target="_blank" class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon"><i class="fas fa-database"></i></span>
                                            <span>Dataset</span>
                                        </a>
                                    </span>
                                    
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section class="hero teaser">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column">
                        <div class="hero-body">
                            
                            <img src="https://NTUneillee.github.io/academic-assets/images/RLAWB_logo.webp" alt="RL-AWB: Deep Reinforcement Learning for Auto White Balance Correction in Low-Light Night-time Scenes" style="width: 100%; display: block;" />
                            
                            
                            <div class="subtitle has-text-centered content" style="width: 100%; margin-top: 1.5rem; line-height: 1.7;">
                                We present <strong>RL-AWB</strong>, the first framework that integrates reinforcement learning into automatic white balance for nighttime color constancy. Our approach fundamentally differs from existing paradigms by formulating AWB as a sequential decision-making problem, where an RL agent learns adaptive parameter selection policies for a novel statistical illuminant estimator.
                            </div>
                            
                        </div>
                    </div>
                </div>
            </div>
        </section>

        
        <section class="section hero is-light">
            <div class="container is-max-desktop">
                <div class="columns is-centered has-text-centered">
                    <div class="column">
                        <h2 class="title is-3">Abstract</h2>
                        <div class="content has-text-justified">
                            <div class="has-text-centered" style="margin: 1.0rem 0;">
    <div class="method-image-container">
        
        <img src="https://NTUneillee.github.io/academic-assets/images/RLAWBteaser.webp" alt="Figure" />
        
        
    </div>
</div>

<p>Nighttime color constancy remains a challenging problem in computational photography due to low-light noise and complex illumination conditions that limit cross-sensor generalization. We present RL-AWB, a novel framework combining statistical methods with deep reinforcement learning for nighttime white balance. Our method begins with a statistical algorithm tailored for nighttime scenes, integrating salient gray pixel detection with novel illumination estimation. Building on this foundation, we develop the first deep reinforcement learning approach for color constancy that leverages the statistical algorithm as its core, mimicking professional AWB tuning experts by dynamically optimizing parameters for each image without knowing its ground-truth illumination. To facilitate cross-sensor evaluation, we introduce the first multi-sensor nighttime color constancy dataset. Experiment results demonstrate that our method achieve superior generalization capability across low-light and well-illuminated images.</p>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        

        <section class="section">
                    <div class="container is-max-desktop">
                        <div class="columns is-centered">
                            <div class="column">
                                <h2 class="title is-3 has-text-centered">Contributions</h2>
                                <div class="content has-text-justified">
                                    <ul>
<li>We develop <strong>SGP-LRD</strong> (Salient Gray Pixels with Local Reflectance Differences), a nighttime-specific color constancy algorithm that achieves state-of-the-art illumination estimation on public nighttime benchmarks.</li>
<li>We design the <strong>RL-AWB</strong> framework with Soft Actor-Critic (SAC) training and two-stage curriculum learning, enabling adaptive per-image parameter optimization with exceptional data efficiency.</li>
<li>We contribute <strong>LEVI</strong> (Low-light Evening Vision Illumination), the first multi-camera nighttime dataset comprising 700 images from two sensors, enabling rigorous cross-sensor color constancy evaluation.</li>
<li>Extensive experiments demonstrate superior cross-sensor generalization over state-of-the-art with only <strong>5</strong> training images per dataset.</li>
</ul>

                                </div>
                            </div>
                        </div>
                    </div>
                </section><section class="section hero is-light">
                    <div class="container is-max-desktop">
                        <div class="columns is-centered">
                            <div class="column">
                                <h2 class="title is-3 has-text-centered">Method Overview</h2>
                                <div class="content has-text-justified">
                                    
<div class="has-text-centered" style="margin: 1.0rem 0;">
    <div class="method-image-container">
        
        <img src="https://NTUneillee.github.io/academic-assets/images/RLAWBflowchart1.webp" alt="**Overview of the proposed RL-AWB framework.** (A) Given an input image, the proposed nighttime color constancy algorithm SGP-LRD estimates the scene illuminant conditioned on two hyper-parameters (gray-pixel sampling percentage N and Minkowski order p). (B) A SAC agent selects parameter updates based on image statistics and current AWB settings. (C) The policy outputs one action per parameter; actions are sampled, squashed by tanh to [−1, 1], and rescaled to valid ranges. (D) The rescaled actions update the two hyper-parameters and are applied to SGP-LRD to produce the illuminant estimate. Repeat until the termination criterion is met." />
        
        
        <p style="margin-top: 1rem; font-size: 0.95rem; color: #666; line-height: 1.6;"><strong>Overview of the proposed RL-AWB framework.</strong> (A) Given an input image, the proposed nighttime color constancy algorithm SGP-LRD estimates the scene illuminant conditioned on two hyper-parameters (gray-pixel sampling percentage N and Minkowski order p). (B) A SAC agent selects parameter updates based on image statistics and current AWB settings. (C) The policy outputs one action per parameter; actions are sampled, squashed by tanh to [−1, 1], and rescaled to valid ranges. (D) The rescaled actions update the two hyper-parameters and are applied to SGP-LRD to produce the illuminant estimate. Repeat until the termination criterion is met.</p>
        
    </div>
</div>


                                </div>
                            </div>
                        </div>
                    </div>
                </section><section class="section">
                    <div class="container is-max-desktop">
                        <div class="columns is-centered">
                            <div class="column">
                                <h2 class="title is-3 has-text-centered">LEVI Dataset</h2>
                                <div class="content has-text-justified">
                                    <div class="has-text-centered" style="margin: 1.0rem 0;">
    <div class="method-image-container">
        
        <img src="https://NTUneillee.github.io/academic-assets/images/LEVI%20full.webp" alt="**Sample images from the proposed LEVI dataset with their corresponding Color Checker mask annotations.** The dataset captures diverse nighttime scenes with complex mixed lighting, low illumination, and high ISO conditions." />
        
        
        <p style="margin-top: 1rem; font-size: 0.95rem; color: #666; line-height: 1.6;"><strong>Sample images from the proposed LEVI dataset with their corresponding Color Checker mask annotations.</strong> The dataset captures diverse nighttime scenes with complex mixed lighting, low illumination, and high ISO conditions.</p>
        
    </div>
</div>


<div class="has-text-centered" style="margin: 1.0rem 0;">
    <div class="method-image-container">
        
        <img src="https://NTUneillee.github.io/academic-assets/images/LEVINCCcomparison.webp" alt="**Illuminant distribution and normalized mean luminance histogram over all the collected nighttime images in the LEVI and NCC datasets.** LEVI complements NCC by covering broader lighting conditions and containing more low- luminance nighttime images, offering a new benchmark for low-light color constancy evaluation." />
        
        
        <p style="margin-top: 1rem; font-size: 0.95rem; color: #666; line-height: 1.6;"><strong>Illuminant distribution and normalized mean luminance histogram over all the collected nighttime images in the LEVI and NCC datasets.</strong> LEVI complements NCC by covering broader lighting conditions and containing more low- luminance nighttime images, offering a new benchmark for low-light color constancy evaluation.</p>
        
    </div>
</div>

<p>Prior to our work, the NCC dataset was the only public nighttime color constancy benchmark, containing 513 images from a single camera. To enable cross-sensor evaluation, we introduce the Low-light Evening Vision Illumination (LEVI) dataset—the first multi-camera nighttime bench- mark comprising 700 linear RAW images from two systems: iPhone 16 Pro (images #1–370, 4320×2160, 12-bit) and Sony ILCE-6400 (images #371–700, 6000×4000, 14-bit), with ISO ranging from 500 to 16,000. Each scene contains a Macbeth Color Checker with manual annotations. Groundtruth illuminants are computed as median RGB values of non-saturated achromatic patches. All images are black-level corrected and converted to linear RGB.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </section><section class="section hero is-light">
                    <div class="container is-max-desktop">
                        <div class="columns is-centered">
                            <div class="column">
                                <h2 class="title is-3 has-text-centered">Results</h2>
                                <div class="content has-text-justified">
                                    
<div class="has-text-centered" style="margin: 1.0rem 0;">
    <div class="method-image-container">
        
        <img src="https://NTUneillee.github.io/academic-assets/images/IndomainResults1.webp" alt="**In-dataset evaluation results on the NCC and LEVI datasets.** Angular error in degrees. Note that images shown are gamma-corrected for visualization." />
        
        
        <p style="margin-top: 1rem; font-size: 0.95rem; color: #666; line-height: 1.6;"><strong>In-dataset evaluation results on the NCC and LEVI datasets.</strong> Angular error in degrees. Note that images shown are gamma-corrected for visualization.</p>
        
    </div>
</div>


<div class="has-text-centered" style="margin: 1.0rem 0;">
    <div class="method-image-container">
        
        <img src="https://NTUneillee.github.io/academic-assets/images/CrossResults1.webp" alt="**Cross-dataset evaluation results between the NCC and LEVI datasets.** Angular error in degrees. Note that $C^5$ (5) and $C^5$ (full) are both trained using the official implementation. $C^5$ (5) denotes the few-shot setting with only five training images per dataset, whereas $C^5$ (full) follows the original 3-fold protocol using all available training images in the datasets." />
        
        
        <p style="margin-top: 1rem; font-size: 0.95rem; color: #666; line-height: 1.6;"><strong>Cross-dataset evaluation results between the NCC and LEVI datasets.</strong> Angular error in degrees. Note that $C^5$ (5) and $C^5$ (full) are both trained using the official implementation. $C^5$ (5) denotes the few-shot setting with only five training images per dataset, whereas $C^5$ (full) follows the original 3-fold protocol using all available training images in the datasets.</p>
        
    </div>
</div>


<div class="has-text-centered" style="margin: 1.0rem 0;">
    <div class="method-image-container">
        
        <img src="https://NTUneillee.github.io/academic-assets/images/GehlerResults1.webp" alt="**Evaluation results on the Gehler-Shi dataset.** Angular error in degrees. $C^4$, $C^5$, and the proposed RL-AWB are trained on the NCC dataset and evaluated on the Gehler–Shi dataset. Compared with our SGP-LRD, the proposed RL-AWB framework achieves a reduction of 5.9\% in the median angular error and 9.8\% in the best-25\% angular error, showing that RL-AWB generalizes well across low-light and well-illuminated images." />
        
        
        <p style="margin-top: 1rem; font-size: 0.95rem; color: #666; line-height: 1.6;"><strong>Evaluation results on the Gehler-Shi dataset.</strong> Angular error in degrees. $C^4$, $C^5$, and the proposed RL-AWB are trained on the NCC dataset and evaluated on the Gehler–Shi dataset. Compared with our SGP-LRD, the proposed RL-AWB framework achieves a reduction of 5.9% in the median angular error and 9.8% in the best-25% angular error, showing that RL-AWB generalizes well across low-light and well-illuminated images.</p>
        
    </div>
</div>


<div class="has-text-centered" style="margin: 1.0rem 0;">
    <div class="method-image-container">
        
        <img src="https://NTUneillee.github.io/academic-assets/images/VisualizationResults.webp" alt="**Qualitative comparison of cross-dataset performance.** Angular error in degrees. Note that images shown are gamma-corrected for visualization. " />
        
        
        <p style="margin-top: 1rem; font-size: 0.95rem; color: #666; line-height: 1.6;"><strong>Qualitative comparison of cross-dataset performance.</strong> Angular error in degrees. Note that images shown are gamma-corrected for visualization.</p>
        
    </div>
</div>


<div class="has-text-centered" style="margin: 1.0rem 0;">
    <div class="method-image-container">
        
        <img src="https://NTUneillee.github.io/academic-assets/images/RLAWBsteps.webp" alt="**Qualitative comparison of cross-dataset performance.** Angular error in degrees. Note that images shown are gamma-corrected for visualization. " />
        
        
        <p style="margin-top: 1rem; font-size: 0.95rem; color: #666; line-height: 1.6;"><strong>Qualitative comparison of cross-dataset performance.</strong> Angular error in degrees. Note that images shown are gamma-corrected for visualization.</p>
        
    </div>
</div>


                                </div>
                            </div>
                        </div>
                    </div>
                </section><section class="section" id="BibTeX">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column">
                        <h2 class="title is-3 has-text-centered">BibTeX</h2>
                        <pre><code>@inproceedings{rlawb2026,
  title = {RL-AWB: Deep Reinforcement Learning for Auto White Balance Correction in Low-Light Night-time Scenes},
  author = {Yuan-Kang Lee and Kuan-Lin Chen and Chia-Che Chang and Yu-Lun Liu},
  booktitle = {under review},
  year = {2026},
  pages = {to appear}
}
</code></pre>
                    </div>
                </div>
            </div>
        </section>
        

        <footer class="footer">
            <div class="container">
                <div class="columns is-centered">
                    <div class="column is-8">
                        <div class="content has-text-centered">
                            <p>
                                This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
                                <br />This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </footer>

        <script>
            
            document.addEventListener('DOMContentLoaded', function() {
                const tables = document.querySelectorAll('.content > table');
                tables.forEach(function(table) {
                    const wrapper = document.createElement('div');
                    wrapper.className = 'table-wrapper';
                    table.parentNode.insertBefore(wrapper, table);
                    wrapper.appendChild(table);
                });
            });
        </script>
    </body>
</html>
